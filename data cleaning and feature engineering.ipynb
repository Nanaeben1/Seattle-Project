{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c92618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of CSV file names\n",
    "csv_files = [\n",
    "    'Electrical_permits_part_1.csv',\n",
    "    'Electrical_permits_part_2.csv',\n",
    "    'Electrical_permits_part_3.csv',\n",
    "    'Electrical_permits_part_4.csv',\n",
    "    'Electrical_permits_part_5.csv',\n",
    "    'Electrical_permits_part_6.csv',\n",
    "    'Electrical_permits_part_7.csv',\n",
    "    'Electrical_permits_part_8.csv'\n",
    "]\n",
    "\n",
    "# Read and concatenate all the CSV files into one DataFrame\n",
    "df_list = [pd.read_csv(file) for file in csv_files]\n",
    "merged_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv('Electrical_permits.csv', index=False)\n",
    "\n",
    "# Optionally, display the first few rows of the merged DataFrame\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc872d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('Electrical_permits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74ea74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('Electrical_permits.csv')\n",
    "\n",
    "# Strip any leading or trailing spaces in column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Print the column names to ensure they are correct\n",
    "print(\"Original columns:\", df.columns)\n",
    "\n",
    "# Check for the presence of the predictor columns\n",
    "if 'PermitClassMapped' not in df.columns or 'PermitTypeMapped' not in df.columns or 'PermitClass' not in df.columns:\n",
    "    raise KeyError(\"The columns 'PermitClass', 'PermitClassMapped', or 'PermitTypeMapped' are not found in the DataFrame\")\n",
    "\n",
    "# Extract rows with and without missing values\n",
    "non_missing_data = df.dropna(subset=['EstProjectCost'])\n",
    "missing_data = df[df['EstProjectCost'].isnull()]\n",
    "\n",
    "# Convert categorical variables to numerical using get_dummies\n",
    "non_missing_data = pd.get_dummies(non_missing_data, columns=['PermitClass', 'PermitClassMapped', 'PermitTypeMapped'])\n",
    "missing_data = pd.get_dummies(missing_data, columns=['PermitClass', 'PermitClassMapped', 'PermitTypeMapped'])\n",
    "\n",
    "# Ensure both datasets have the same dummy variable columns\n",
    "missing_data = missing_data.reindex(columns=non_missing_data.columns, fill_value=0)\n",
    "\n",
    "# Print the columns after get_dummies to ensure they match\n",
    "print(\"Non-missing data columns after get_dummies:\", non_missing_data.columns)\n",
    "print(\"Missing data columns after reindex:\", missing_data.columns)\n",
    "\n",
    "# Choose predictors - update this list based on the actual dummy columns created\n",
    "predictors = [col for col in non_missing_data.columns if col.startswith('PermitClass_') or col.startswith('PermitClassMapped_') or col.startswith('PermitTypeMapped_')]\n",
    "\n",
    "# Train the regression model\n",
    "model = LinearRegression()\n",
    "model.fit(non_missing_data[predictors], non_missing_data['EstProjectCost'])\n",
    "\n",
    "# Predict the missing values\n",
    "predicted_values = model.predict(missing_data[predictors])\n",
    "\n",
    "# Fill in the missing values with the predicted values\n",
    "df.loc[df['EstProjectCost'].isnull(), 'EstProjectCost'] = predicted_values\n",
    "\n",
    "# Verify if the missing values are filled\n",
    "print(df['EstProjectCost'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959b2a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('Electrical_permits.csv')\n",
    "\n",
    "# Strip any leading or trailing spaces in column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Print the column names to ensure they are correct\n",
    "print(\"Original columns:\", df.columns)\n",
    "\n",
    "# Check for the presence of the predictor columns\n",
    "if 'PermitClassMapped' not in df.columns or 'PermitTypeMapped' not in df.columns or 'PermitClass' not in df.columns:\n",
    "    raise KeyError(\"The columns 'PermitClass', 'PermitClassMapped', or 'PermitTypeMapped' are not found in the DataFrame\")\n",
    "\n",
    "# Extract rows with and without missing values in EstProjectCost\n",
    "non_missing_data = df.dropna(subset=['EstProjectCost'])\n",
    "missing_data = df[df['EstProjectCost'].isnull()]\n",
    "\n",
    "# Convert categorical variables to numerical using get_dummies\n",
    "non_missing_data = pd.get_dummies(non_missing_data, columns=['PermitClass', 'PermitClassMapped', 'PermitTypeMapped'])\n",
    "missing_data = pd.get_dummies(missing_data, columns=['PermitClass', 'PermitClassMapped', 'PermitTypeMapped'])\n",
    "\n",
    "# Ensure both datasets have the same dummy variable columns\n",
    "missing_data = missing_data.reindex(columns=non_missing_data.columns, fill_value=0)\n",
    "\n",
    "# Print the columns after get_dummies to ensure they match\n",
    "print(\"Non-missing data columns after get_dummies:\", non_missing_data.columns)\n",
    "print(\"Missing data columns after reindex:\", missing_data.columns)\n",
    "\n",
    "# Choose predictors - update this list based on the actual dummy columns created\n",
    "predictors = [col for col in non_missing_data.columns if col.startswith('PermitClass_') or col.startswith('PermitClassMapped_') or col.startswith('PermitTypeMapped_')]\n",
    "\n",
    "# Train the regression model\n",
    "model = LinearRegression()\n",
    "model.fit(non_missing_data[predictors], non_missing_data['EstProjectCost'])\n",
    "\n",
    "# Predict the missing values\n",
    "predicted_values = model.predict(missing_data[predictors])\n",
    "\n",
    "# Fill in the missing values with the predicted values\n",
    "df.loc[df['EstProjectCost'].isnull(), 'EstProjectCost'] = predicted_values\n",
    "\n",
    "# Fill other missing values using backfill or forward fill\n",
    "df.fillna(method='bfill', inplace=True)\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Define thresholds\n",
    "single_family_threshold = 15000000  # 15 million\n",
    "multi_family_threshold = 50000000   # 50 million\n",
    "\n",
    "# Check unique values in 'PermitClass' to ensure categories are correct\n",
    "print(\"Unique values in 'PermitClass':\", df['PermitClass'].unique())\n",
    "\n",
    "# Print descriptive statistics for 'EstProjectCost'\n",
    "print(\"Descriptive statistics for 'EstProjectCost':\")\n",
    "print(df['EstProjectCost'].describe())\n",
    "\n",
    "# Print the number of rows before filtering\n",
    "print(\"Number of rows before filtering:\", len(df))\n",
    "\n",
    "# Filter rows based on the conditions\n",
    "filtered_df = df[\n",
    "    ~(\n",
    "        ((df['PermitClass'] == 'Single Family/Duplex') & (df['EstProjectCost'] > single_family_threshold)) |\n",
    "        ((df['PermitClass'] == 'MultiFamily') & (df['EstProjectCost'] > multi_family_threshold))\n",
    "    )\n",
    "]\n",
    "\n",
    "# Print the number of rows after filtering\n",
    "print(\"Number of rows after filtering:\", len(filtered_df))\n",
    "\n",
    "# Verify if the missing values are filled\n",
    "print(filtered_df.isnull().sum())\n",
    "\n",
    "# Save the cleaned dataset to a new CSV file\n",
    "filtered_df.to_csv('Cleaned_Electrical_permits55.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a68d1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb318c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf24d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert date columns to datetime with error handling\n",
    "date_columns = ['AppliedDate', 'IssuedDate', 'ExpiresDate', 'CompletedDate']\n",
    "for col in date_columns:\n",
    "    filtered_df[col] = pd.to_datetime(filtered_df[col], errors='coerce')\n",
    "\n",
    "# Verify if the datetime conversion was successful\n",
    "print(filtered_df[date_columns].dtypes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e13f12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['ApplicationToIssueTime'] = (filtered_df['IssuedDate'] - filtered_df['AppliedDate']).dt.days\n",
    "filtered_df['IssueToCompletionTime'] = (filtered_df['CompletedDate'] - filtered_df['IssuedDate']).dt.days\n",
    "filtered_df['TotalPermitTime'] = (filtered_df['CompletedDate'] - filtered_df['AppliedDate']).dt.days\n",
    "filtered_df['AppliedYear'] = filtered_df['AppliedDate'].dt.year\n",
    "filtered_df['AppliedMonth'] = filtered_df['AppliedDate'].dt.month\n",
    "filtered_df['AppliedDay'] = filtered_df['AppliedDate'].dt.day\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
